{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11505587,"sourceType":"datasetVersion","datasetId":7213882}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SCRAPING Subslikescript for movie scripts","metadata":{}},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:33:24.549316Z","iopub.execute_input":"2025-05-07T09:33:24.549929Z","iopub.status.idle":"2025-05-07T09:33:32.318341Z","shell.execute_reply.started":"2025-05-07T09:33:24.549904Z","shell.execute_reply":"2025-05-07T09:33:32.317388Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.11.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport os\nimport time\nimport json\nimport zipfile\nimport os\nimport pandas as pd\nimport faiss\nimport numpy as np\nfrom nltk.tokenize import sent_tokenize\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import pipeline\nimport torch  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:33:37.725088Z","iopub.execute_input":"2025-05-07T09:33:37.725902Z","iopub.status.idle":"2025-05-07T09:34:22.550509Z","shell.execute_reply.started":"2025-05-07T09:33:37.725873Z","shell.execute_reply":"2025-05-07T09:34:22.549950Z"}},"outputs":[{"name":"stderr","text":"2025-05-07 09:34:01.924430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746610442.375197      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746610442.480875      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Base URL of Subslikescript\nBASE_URL = \"https://subslikescript.com\"\nMOVIE_LIST_URL = f\"{BASE_URL}/movies_letter-\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:33:06.169396Z","iopub.status.idle":"2025-05-07T09:33:06.169744Z","shell.execute_reply.started":"2025-05-07T09:33:06.169571Z","shell.execute_reply":"2025-05-07T09:33:06.169587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_movie_links(letter='A'):\n#     \"\"\"Scrapes movie page links from a letter page (A-Z)\"\"\"\n#     url = f\"{MOVIE_LIST_URL}{letter}\"\n#     res = requests.get(url)\n#     soup = BeautifulSoup(res.text, 'html.parser')\n#     links = soup.select('a[href^=\"/movie/\"]')\n#     movie_links = [BASE_URL + a['href'] for a in links]\n#     return movie_links","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:56:11.518809Z","iopub.execute_input":"2025-05-07T08:56:11.519086Z","iopub.status.idle":"2025-05-07T08:56:11.544439Z","shell.execute_reply.started":"2025-05-07T08:56:11.519068Z","shell.execute_reply":"2025-05-07T08:56:11.543704Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# def get_script(url):\n#     \"\"\"Extracts movie title and script text from a movie page\"\"\"\n#     res = requests.get(url)\n#     soup = BeautifulSoup(res.text, 'html.parser')\n#     title_tag = soup.find('h1')\n#     script_div = soup.find('div', class_='full-script')\n#     if not title_tag or not script_div:\n#         return None, None\n#     title = title_tag.text.strip()\n#     script = script_div.get_text(separator=\"\\n\").strip()\n#     return title, script\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:56:11.545105Z","iopub.execute_input":"2025-05-07T08:56:11.545390Z","iopub.status.idle":"2025-05-07T08:56:11.560005Z","shell.execute_reply.started":"2025-05-07T08:56:11.545370Z","shell.execute_reply":"2025-05-07T08:56:11.559394Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# def scrape_and_save_to_json(letter='A', max_movies=5, output_file='scripts.json'):\n#     \"\"\"Scrapes scripts and saves them as a list of dicts (RAG-ready)\"\"\"\n#     links = get_movie_links(letter)\n#     all_scripts = []\n\n#     for i, link in enumerate(links[:max_movies]):\n#         try:\n#             title, script = get_script(link)\n#             if titale and script:\n#                 all_scripts.append({\n#                     \"title\": title,\n#                     \"content\": script,\n#                     \"source\": link\n#                 })\n#                 print(f\"âœ… Scraped: {title}\")\n#             else:\n#                 print(f\"âŒ Skipped (no script): {link}\")\n#         except Exception as e:\n#             print(f\"âš ï¸ Error with {link}: {e}\")\n#         time.sleep(1)  \n\n#     with open(output_file, 'w', encoding='utf-8') as f:\n#         json.dump(all_scripts, f, ensure_ascii=False, indent=2)\n#     print(f\"\\nğŸ“ Saved {len(all_scripts)} scripts to {output_file}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:56:11.560657Z","iopub.execute_input":"2025-05-07T08:56:11.560925Z","iopub.status.idle":"2025-05-07T08:56:11.577108Z","shell.execute_reply.started":"2025-05-07T08:56:11.560903Z","shell.execute_reply":"2025-05-07T08:56:11.576423Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# for letter in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n#     scrape_and_save_to_json(letter=letter, max_movies=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:56:11.577728Z","iopub.execute_input":"2025-05-07T08:56:11.578045Z","iopub.status.idle":"2025-05-07T08:56:11.595562Z","shell.execute_reply.started":"2025-05-07T08:56:11.578019Z","shell.execute_reply":"2025-05-07T08:56:11.595034Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# RAG","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:36.686005Z","iopub.execute_input":"2025-05-07T09:34:36.687145Z","iopub.status.idle":"2025-05-07T09:34:36.963381Z","shell.execute_reply.started":"2025-05-07T09:34:36.687119Z","shell.execute_reply":"2025-05-07T09:34:36.962509Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"with open('/kaggle/input/moviescripts/scripts.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:36.964698Z","iopub.execute_input":"2025-05-07T09:34:36.964968Z","iopub.status.idle":"2025-05-07T09:34:36.992482Z","shell.execute_reply.started":"2025-05-07T09:34:36.964950Z","shell.execute_reply":"2025-05-07T09:34:36.991763Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"chunks = []\nfor movie in data:\n    text = movie['content']\n    sentences = sent_tokenize(text)\n    chunk, temp = [], []\n    for sent in sentences:\n        words = sent.split()\n        if len(' '.join(temp + words).split()) <= 100:\n            temp.extend(words)\n        else:\n            chunks.append(' '.join(temp))\n            temp = words[-20:]  # small overlap\n    if temp:\n        chunks.append(' '.join(temp))\n\nprint(f\"ğŸ”¹ Total chunks: {len(chunks)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:43.129277Z","iopub.execute_input":"2025-05-07T09:34:43.129637Z","iopub.status.idle":"2025-05-07T09:34:43.421212Z","shell.execute_reply.started":"2025-05-07T09:34:43.129613Z","shell.execute_reply":"2025-05-07T09:34:43.420565Z"}},"outputs":[{"name":"stdout","text":"ğŸ”¹ Total chunks: 662\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"chunks = [chunk.item() if isinstance(chunk, np.ndarray) else str(chunk) for chunk in chunks]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:45.026724Z","iopub.execute_input":"2025-05-07T09:34:45.027020Z","iopub.status.idle":"2025-05-07T09:34:45.031344Z","shell.execute_reply.started":"2025-05-07T09:34:45.026998Z","shell.execute_reply":"2025-05-07T09:34:45.030482Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')\nembeddings = model.encode(chunks, show_progress_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:45.363443Z","iopub.execute_input":"2025-05-07T09:34:45.364138Z","iopub.status.idle":"2025-05-07T09:34:54.331404Z","shell.execute_reply.started":"2025-05-07T09:34:45.364109Z","shell.execute_reply":"2025-05-07T09:34:54.330599Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e598ca0cb24c12b529645bfc350aba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"323137b1ab544cb394f1bbf32e7a7530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ee4cb6686846d2a95b9d29dab1238f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02e4712f23e742cc8ff1e6aa0e41664b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"484fbab69a1240929b692ac4c76b256e"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35661d911a3b4976a9a23d0ba6f6a900"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7211454f9804b909648d3f9606db827"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"611201093e6c4c1591bad57612e53517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59e10ecc67f94451aa6a3c96658c5187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42bbb0288c84f888dc4c1c4ba7974c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b8f2f87fb48406b82280582bca2587c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/21 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19e6c5fa6e3a4fb7a078b0179bd153c4"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Build FAISS Index\ndim = embeddings.shape[1]\nindex = faiss.IndexFlatL2(dim)\nindex.add(np.array(embeddings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:55.693967Z","iopub.execute_input":"2025-05-07T09:34:55.694727Z","iopub.status.idle":"2025-05-07T09:34:55.700511Z","shell.execute_reply.started":"2025-05-07T09:34:55.694704Z","shell.execute_reply":"2025-05-07T09:34:55.699664Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"generator = pipeline(\"text-generation\", model=\"gpt2\", max_length=5000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:34:57.872032Z","iopub.execute_input":"2025-05-07T09:34:57.872301Z","iopub.status.idle":"2025-05-07T09:35:02.043124Z","shell.execute_reply.started":"2025-05-07T09:34:57.872282Z","shell.execute_reply":"2025-05-07T09:35:02.042182Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06565a78d08e4924b42c8179d0dd696a"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699a2ea4317c4548ae3c30f4c6f960c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820ac23abee44c15ac08e251c668688d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"462cb0bb051f4426813bfbb1c15659a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c25b2099eea4401e99521f3a45fa9e4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4e3fc04a5d49aa9eb7304da2d00f3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dd5644115fa4cf48adb4194796316cd"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pylibcugraph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:35:02.044450Z","iopub.execute_input":"2025-05-07T09:35:02.044763Z","iopub.status.idle":"2025-05-07T09:35:05.674511Z","shell.execute_reply.started":"2025-05-07T09:35:02.044743Z","shell.execute_reply":"2025-05-07T09:35:05.673518Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pip install -U bitsandbytes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:35:07.207577Z","iopub.execute_input":"2025-05-07T09:35:07.208320Z","iopub.status.idle":"2025-05-07T09:36:42.362901Z","shell.execute_reply.started":"2025-05-07T09:35:07.208295Z","shell.execute_reply":"2025-05-07T09:36:42.362103Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:36:42.364421Z","iopub.execute_input":"2025-05-07T09:36:42.364702Z","iopub.status.idle":"2025-05-07T09:36:42.368925Z","shell.execute_reply.started":"2025-05-07T09:36:42.364679Z","shell.execute_reply":"2025-05-07T09:36:42.368302Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!git config --global credential.helper store","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:36:42.369720Z","iopub.execute_input":"2025-05-07T09:36:42.370014Z","iopub.status.idle":"2025-05-07T09:36:42.551228Z","shell.execute_reply.started":"2025-05-07T09:36:42.369990Z","shell.execute_reply":"2025-05-07T09:36:42.550062Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:37:09.947101Z","iopub.execute_input":"2025-05-07T09:37:09.947368Z","iopub.status.idle":"2025-05-07T09:37:09.965337Z","shell.execute_reply.started":"2025-05-07T09:37:09.947350Z","shell.execute_reply":"2025-05-07T09:37:09.964418Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be5377ba3544ac182f318cbcbc66f36"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model_id = \"meta-llama/Llama-2-7b-chat-hf\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:37:17.120691Z","iopub.execute_input":"2025-05-07T09:37:17.121627Z","iopub.status.idle":"2025-05-07T09:37:17.125202Z","shell.execute_reply.started":"2025-05-07T09:37:17.121596Z","shell.execute_reply":"2025-05-07T09:37:17.124463Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:37:17.958760Z","iopub.execute_input":"2025-05-07T09:37:17.959548Z","iopub.status.idle":"2025-05-07T09:37:17.963177Z","shell.execute_reply.started":"2025-05-07T09:37:17.959492Z","shell.execute_reply":"2025-05-07T09:37:17.962592Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:37:21.906488Z","iopub.execute_input":"2025-05-07T09:37:21.907153Z","iopub.status.idle":"2025-05-07T09:38:21.005279Z","shell.execute_reply.started":"2025-05-07T09:37:21.907131Z","shell.execute_reply":"2025-05-07T09:38:21.004328Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c81b57e553be45e0b5eba79a07758931"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de1042a3117e4b00a8275fefa03f3f4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5acc506cd3da4d21a43222fe14207206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f09733cbc5df4d1fa9029d4313187e5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc8f58bf3af9482eb823a5f17723d222"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74b7146ab021456a8c0c608e6f0ce544"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fb23b154b9a44ef88a0277ce2747657"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f441a425e46a43e29e63f32c46e2bd48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eeb5562bdf34caa86f67fdaa393e43d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cabf6757464b5d8d1cdf2092862ecd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d73dd22fb0314eeab750ef27069adc12"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"generator = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=1024,\n    truncation=True,  \n    do_sample=True,\n    temperature=0.7,\n    repetition_penalty=1.1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:38:28.871569Z","iopub.execute_input":"2025-05-07T09:38:28.871887Z","iopub.status.idle":"2025-05-07T09:38:28.891232Z","shell.execute_reply.started":"2025-05-07T09:38:28.871863Z","shell.execute_reply":"2025-05-07T09:38:28.890572Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!pip install gradio\n\nimport gradio as gr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:38:31.036678Z","iopub.execute_input":"2025-05-07T09:38:31.036970Z","iopub.status.idle":"2025-05-07T09:38:43.859669Z","shell.execute_reply.started":"2025-05-07T09:38:31.036950Z","shell.execute_reply":"2025-05-07T09:38:43.858825Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.10.0 (from gradio)\n  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (14.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom typing import List, Tuple, Optional\nimport gradio as gr\n\ndef get_relevant_context(query: str, k: int = 3) -> str:\n    try:\n        # Convert query to embedding\n        query_embedding = model.encode([query], convert_to_tensor=True)\n        # Convert to numpy and ensure correct shape\n        query_np = query_embedding.cpu().numpy().astype('float32')\n        \n        # Ensure query is 2D for FAISS\n        if len(query_np.shape) == 1:\n            query_np = query_np.reshape(1, -1)\n            \n        # Search in FAISS\n        distances, indices = index.search(query_np, k)\n        \n        # Safely get chunks\n        relevant_chunks = []\n        for idx in indices[0]:\n            if 0 <= idx < len(chunks):\n                relevant_chunks.append(chunks[idx])\n        \n        return \" \".join(relevant_chunks) if relevant_chunks else \"\"\n        \n    except Exception as e:\n        print(f\"Error in get_relevant_context: {str(e)}\")\n        return \"\"\n\ndef generate_response(message: str, history: Optional[List[dict]] = None) -> str:\n    try:\n        # Input validation\n        if not isinstance(message, str) or not message.strip():\n            return \"Please provide a valid question.\"\n            \n        # Get context\n        context = get_relevant_context(message)\n        \n        # Create prompt with proper formatting\n        prompt = f\"\"\"Context: {context}\n\nQuestion: {message}\n\nAnswer: Let me help you with that.\"\"\"\n\n        # Generate response with proper error handling\n        with torch.no_grad():  # Ensure no gradients are computed\n            response = generator(\n                prompt,\n                max_length=500,\n                num_return_sequences=1,\n                pad_token_id=tokenizer.pad_token_id,\n                eos_token_id=tokenizer.eos_token_id,\n                do_sample=True,\n                temperature=0.7,\n                top_p=0.95,\n            )\n\n        # Extract and clean response\n        generated_text = response[0]['generated_text']\n        answer = generated_text.split(\"Answer:\")[-1].strip()\n        \n        # Ensure we have a valid response\n        if not answer:\n            answer = \"I apologize, but I couldn't generate a proper response. Please try rephrasing your question.\"\n            \n        return answer\n\n    except Exception as e:\n        print(f\"Error in generate_response: {str(e)}\")\n        return \"I encountered an error while processing your request. Please try again.\"\n\n# Create theme and configure interface\ntheme = gr.themes.Soft(\n    primary_hue=\"blue\",\n    secondary_hue=\"gray\",\n)\n\n# Create Gradio interface with error handling\ntry:\n    demo = gr.ChatInterface(\n        fn=generate_response,\n        title=\"Movie Script Chatbot\",\n        description=\"Ask me anything about movies in the database!\",\n        theme=theme,\n        examples=[\n            \"What happens in the opening scene?\",\n            \"Tell me about the main character's journey\",\n            \"What are some memorable quotes?\",\n        ],\n        chatbot=gr.Chatbot(type=\"messages\")  # Updated to use new message format\n    )\n\n    # Launch with proper configuration\n    demo.launch(\n        share=True,\n        debug=True,\n        server_name=\"0.0.0.0\",\n        server_port=None,  # Let Gradio find an available port\n        show_error=True\n    )\n    \nexcept Exception as e:\n    print(f\"Error setting up Gradio interface: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:38:55.917469Z","iopub.execute_input":"2025-05-07T09:38:55.918172Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:321: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://0.0.0.0:7860\n* Running on public URL: https://2d7ba1156c2cc86186.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://2d7ba1156c2cc86186.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error in get_relevant_context: 'LlamaForCausalLM' object has no attribute 'encode'\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error in get_relevant_context: 'LlamaForCausalLM' object has no attribute 'encode'\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error in get_relevant_context: 'LlamaForCausalLM' object has no attribute 'encode'\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error in get_relevant_context: 'LlamaForCausalLM' object has no attribute 'encode'\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Error in get_relevant_context: 'LlamaForCausalLM' object has no attribute 'encode'\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}